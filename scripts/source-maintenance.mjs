#!/usr/bin/env node

/**
 * Step 3: ã‚½ãƒ¼ã‚¹å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ 
 * 
 * æ©Ÿèƒ½:
 * 1. ã‚½ãƒ¼ã‚¹ä¿¡é ¼åº¦ã®æœˆæ¬¡æ›´æ–°ï¼ˆåˆ©ç”¨é »åº¦ãƒ»æˆåŠŸç‡ãƒ™ãƒ¼ã‚¹ï¼‰
 * 2. æ–°è¦ã‚½ãƒ¼ã‚¹è‡ªå‹•ç™ºè¦‹ãƒ»è¿½åŠ 
 * 3. éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹ã®æ¤œå‡º
 * 4. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
 */

import { createClient } from '@supabase/supabase-js'
import fs from 'fs'

// .env.localèª­ã¿è¾¼ã¿
try {
  const envContent = fs.readFileSync('.env.local', 'utf8')
  envContent.split('\n').forEach(line => {
    if (line.trim() && !line.startsWith('#')) {
      const [key, value] = line.split('=')
      if (key && value) {
        process.env[key.trim()] = value.trim()
      }
    }
  })
} catch (error) {
  console.warn('Warning: .env.local not found, using system environment variables')
}

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
)

/**
 * 1. ã‚½ãƒ¼ã‚¹åˆ©ç”¨çŠ¶æ³åˆ†æãƒ»ä¿¡é ¼åº¦æ›´æ–°
 */
async function updateSourceCredibility() {
  console.log('\nğŸ”„ ã‚½ãƒ¼ã‚¹ä¿¡é ¼åº¦æ›´æ–°ä¸­...')
  
  try {
    // éå»30æ—¥ã®è¨˜äº‹ã¨ã‚½ãƒ¼ã‚¹åˆ©ç”¨çŠ¶æ³å–å¾—
    const { data: usageStats, error: usageError } = await supabase
      .from('contents')
      .select(`
        primary_source_id,
        sources!inner(name, domain, source_type, credibility_score),
        created_at
      `)
      .gte('created_at', new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString())
      .not('primary_source_id', 'is', null)

    if (usageError) {
      console.error('åˆ©ç”¨çŠ¶æ³å–å¾—ã‚¨ãƒ©ãƒ¼:', usageError)
      return
    }

    // ã‚½ãƒ¼ã‚¹åˆ¥åˆ©ç”¨å›æ•°é›†è¨ˆ
    const sourceUsage = {}
    usageStats.forEach(article => {
      const sourceId = article.primary_source_id
      if (!sourceUsage[sourceId]) {
        sourceUsage[sourceId] = {
          source: article.sources,
          count: 0,
          recentUsage: []
        }
      }
      sourceUsage[sourceId].count++
      sourceUsage[sourceId].recentUsage.push(article.created_at)
    })

    // ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯
    const updates = []
    for (const [sourceId, usage] of Object.entries(sourceUsage)) {
      const source = usage.source
      let newScore = source.credibility_score
      
      // åˆ©ç”¨é »åº¦ã«ã‚ˆã‚‹èª¿æ•´
      if (usage.count >= 10) {
        newScore = Math.min(10, newScore + 0.5) // é«˜é »åº¦åˆ©ç”¨ã§+0.5
      } else if (usage.count >= 5) {
        newScore = Math.min(10, newScore + 0.2) // ä¸­é »åº¦åˆ©ç”¨ã§+0.2
      } else if (usage.count === 0) {
        newScore = Math.max(1, newScore - 0.3) // æœªåˆ©ç”¨ã§-0.3
      }

      // ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹åŸºæº–èª¿æ•´
      if (source.source_type === 'primary' && newScore < 7) {
        newScore = 7 // ä¸€æ¬¡ã‚½ãƒ¼ã‚¹ã¯æœ€ä½7ç‚¹ä¿è¨¼
      }

      if (newScore !== source.credibility_score) {
        updates.push({
          id: sourceId,
          oldScore: source.credibility_score,
          newScore: Math.round(newScore * 10) / 10, // å°æ•°ç‚¹1æ¡
          usage: usage.count
        })
      }
    }

    // DBæ›´æ–°å®Ÿè¡Œ
    for (const update of updates) {
      const { error: updateError } = await supabase
        .from('sources')
        .update({ credibility_score: update.newScore })
        .eq('id', update.id)

      if (!updateError) {
        console.log(`âœ… ${update.id}: ${update.oldScore} â†’ ${update.newScore} (åˆ©ç”¨${update.usage}å›)`)
      }
    }

    console.log(`âœ… ä¿¡é ¼åº¦æ›´æ–°å®Œäº†: ${updates.length}ä»¶`)
    return updates

  } catch (error) {
    console.error('ä¿¡é ¼åº¦æ›´æ–°ã‚¨ãƒ©ãƒ¼:', error)
    return []
  }
}

/**
 * 2. æ–°è¦ã‚½ãƒ¼ã‚¹è‡ªå‹•ç™ºè¦‹
 */
async function discoverNewSources() {
  console.log('\nğŸ” æ–°è¦ã‚½ãƒ¼ã‚¹ç™ºè¦‹ä¸­...')
  
  try {
    // éå»7æ—¥ã®è¨˜äº‹ã§æœªåˆ†é¡ã®ã‚½ãƒ¼ã‚¹URLæŠ½å‡º
    const { data: articles, error } = await supabase
      .from('contents')
      .select('slug, body_markdown')
      .gte('created_at', new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString())
      .not('body_markdown', 'is', null)

    if (error) {
      console.error('è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼:', error)
      return []
    }

    // æ—¢å­˜ã‚½ãƒ¼ã‚¹ä¸€è¦§å–å¾—
    const { data: existingSources } = await supabase
      .from('sources')
      .select('domain')

    const existingDomains = new Set(existingSources?.map(s => s.domain) || [])
    
    // æ–°è¦ãƒ‰ãƒ¡ã‚¤ãƒ³ç™ºè¦‹ï¼ˆMarkdownã‹ã‚‰ãƒªãƒ³ã‚¯æŠ½å‡ºï¼‰
    const newDomains = new Set()
    articles.forEach(article => {
      if (article.body_markdown) {
        // Markdownãƒªãƒ³ã‚¯æŠ½å‡º: [text](url) ã¾ãŸã¯ç›´æ¥URL
        const linkRegex = /\[([^\]]*)\]\(([^)]+)\)|https?:\/\/[^\s)]+/g
        let match
        while ((match = linkRegex.exec(article.body_markdown)) !== null) {
          const url = match[2] || match[0] // [text](url) or direct URL
          try {
            const domain = new URL(url).hostname.replace('www.', '')
            if (!existingDomains.has(domain) && !newDomains.has(domain)) {
              newDomains.add(domain)
            }
          } catch (e) {
            // ç„¡åŠ¹ãªURLç„¡è¦–
          }
        }
      }
    })

    // æ–°è¦ã‚½ãƒ¼ã‚¹è‡ªå‹•åˆ†é¡ãƒ»è¿½åŠ 
    const newSources = []
    for (const domain of newDomains) {
      const sourceType = classifySourceType(domain)
      const credibilityScore = calculateInitialCredibility(domain, sourceType)
      
      const newSource = {
        name: formatSourceName(domain),
        domain: domain,
        url: `https://${domain}`,
        source_type: sourceType,
        credibility_score: credibilityScore,
        verification_level: sourceType === 'primary' ? 'official' : 'editorial',
        description: `Auto-discovered ${sourceType} source`,
        created_at: new Date().toISOString()
      }

      // DBè¿½åŠ 
      const { data, error: insertError } = await supabase
        .from('sources')
        .insert(newSource)
        .select()

      if (!insertError) {
        newSources.push(newSource)
        console.log(`âœ… æ–°è¦ã‚½ãƒ¼ã‚¹è¿½åŠ : ${newSource.name} (${sourceType}, ä¿¡é ¼åº¦${credibilityScore})`)
      } else {
        console.log(`âŒ è¿½åŠ å¤±æ•—: ${newSource.name} - ${insertError.message}`)
      }
    }

    console.log(`âœ… æ–°è¦ã‚½ãƒ¼ã‚¹ç™ºè¦‹å®Œäº†: ${newSources.length}ä»¶`)
    return newSources

  } catch (error) {
    console.error('æ–°è¦ã‚½ãƒ¼ã‚¹ç™ºè¦‹ã‚¨ãƒ©ãƒ¼:', error)
    return []
  }
}

/**
 * ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ†é¡
 */
function classifySourceType(domain) {
  // ä¸€æ¬¡ã‚½ãƒ¼ã‚¹ï¼ˆå…¬å¼ãƒ–ãƒ­ã‚°ãƒ»æ–‡æ›¸ï¼‰
  const primaryPatterns = [
    'blog.openai.com', 'anthropic.com', 'blog.anthropic.com',
    'developers.google.com', 'ai.google.com', 'blog.google.com',
    'engineering.fb.com', 'about.fb.com',
    'blogs.microsoft.com', 'azure.microsoft.com',
    'research.nvidia.com', 'developer.nvidia.com'
  ]
  
  // äºŒæ¬¡ã‚½ãƒ¼ã‚¹ï¼ˆæŠ€è¡“ãƒ¡ãƒ‡ã‚£ã‚¢ï¼‰
  const secondaryPatterns = [
    'techcrunch.com', 'arstechnica.com', 'theverge.com',
    'wired.com', 'venturebeat.com', 'reuters.com',
    'bloomberg.com', 'wsj.com'
  ]

  if (primaryPatterns.some(p => domain.includes(p))) {
    return 'primary'
  } else if (secondaryPatterns.some(p => domain.includes(p))) {
    return 'secondary'
  } else {
    return 'tertiary'
  }
}

/**
 * åˆæœŸä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ç®—å‡º
 */
function calculateInitialCredibility(domain, sourceType) {
  let baseScore
  switch (sourceType) {
    case 'primary': baseScore = 9; break
    case 'secondary': baseScore = 7; break
    case 'tertiary': baseScore = 5; break
    default: baseScore = 5
  }

  // ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åˆ¥èª¿æ•´
  if (domain.includes('github.com')) baseScore = Math.max(baseScore, 8)
  if (domain.includes('arxiv.org')) baseScore = Math.max(baseScore, 9)
  if (domain.includes('reddit.com')) baseScore = 6
  if (domain.includes('twitter.com') || domain.includes('x.com')) baseScore = 5

  return baseScore
}

/**
 * ã‚½ãƒ¼ã‚¹åãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
 */
function formatSourceName(domain) {
  const nameMap = {
    'techcrunch.com': 'TechCrunch',
    'theverge.com': 'The Verge',
    'arstechnica.com': 'Ars Technica',
    'venturebeat.com': 'VentureBeat',
    'github.com': 'GitHub',
    'arxiv.org': 'arXiv',
    'reddit.com': 'Reddit'
  }
  
  return nameMap[domain] || domain.charAt(0).toUpperCase() + domain.slice(1)
}

/**
 * 3. éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹æ¤œå‡º
 */
async function detectInactiveSources() {
  console.log('\nğŸ“Š éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹æ¤œå‡ºä¸­...')
  
  try {
    // éå»90æ—¥é–“åˆ©ç”¨ã•ã‚Œã¦ã„ãªã„ã‚½ãƒ¼ã‚¹æ¤œå‡º
    const { data: inactiveSources, error } = await supabase
      .from('sources')
      .select(`
        id, name, domain, source_type,
        contents!left(primary_source_id, created_at)
      `)
      .filter('contents.created_at', 'gte', new Date(Date.now() - 90 * 24 * 60 * 60 * 1000).toISOString())

    if (error) {
      console.error('éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹æ¤œå‡ºã‚¨ãƒ©ãƒ¼:', error)
      return []
    }

    const inactive = inactiveSources.filter(source => 
      !source.contents || source.contents.length === 0
    )

    console.log(`ğŸ“Š 90æ—¥é–“æœªåˆ©ç”¨ã‚½ãƒ¼ã‚¹: ${inactive.length}ä»¶`)
    inactive.forEach(source => {
      console.log(`  - ${source.name} (${source.domain})`)
    })

    return inactive

  } catch (error) {
    console.error('éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹æ¤œå‡ºã‚¨ãƒ©ãƒ¼:', error)
    return []
  }
}

/**
 * 4. ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
 */
async function generateMaintenanceReport(credibilityUpdates, newSources, inactiveSources) {
  const report = {
    timestamp: new Date().toISOString(),
    credibility_updates: credibilityUpdates.length,
    new_sources_added: newSources.length,
    inactive_sources_found: inactiveSources.length,
    details: {
      credibility_updates: credibilityUpdates,
      new_sources: newSources.map(s => ({ name: s.name, domain: s.domain, type: s.source_type })),
      inactive_sources: inactiveSources.map(s => ({ name: s.name, domain: s.domain }))
    }
  }

  // ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
  const reportPath = `maintenance-report-${new Date().toISOString().split('T')[0]}.json`
  await import('fs').then(fs => 
    fs.writeFileSync(reportPath, JSON.stringify(report, null, 2))
  )

  console.log('\nğŸ“‹ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ:')
  console.log(`ğŸ“… å®Ÿè¡Œæ™‚åˆ»: ${report.timestamp}`)
  console.log(`ğŸ”„ ä¿¡é ¼åº¦æ›´æ–°: ${report.credibility_updates}ä»¶`)
  console.log(`ğŸ†• æ–°è¦ã‚½ãƒ¼ã‚¹: ${report.new_sources_added}ä»¶`)
  console.log(`ğŸ’¤ éã‚¢ã‚¯ãƒ†ã‚£ãƒ–: ${report.inactive_sources_found}ä»¶`)
  console.log(`ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: ${reportPath}`)

  return report
}

/**
 * ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
 */
async function main() {
  console.log('ğŸ› ï¸  ã‚½ãƒ¼ã‚¹å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹é–‹å§‹')
  console.log('=====================================')

  try {
    const credibilityUpdates = await updateSourceCredibility()
    const newSources = await discoverNewSources()
    const inactiveSources = await detectInactiveSources()
    const report = await generateMaintenanceReport(credibilityUpdates, newSources, inactiveSources)

    console.log('\nâœ… å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Œäº†!')
    return report

  } catch (error) {
    console.error('ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:', error)
    process.exit(1)
  }
}

// CLIå®Ÿè¡Œæ™‚
if (import.meta.url === `file://${process.argv[1]}`) {
  main()
}

export { main as sourceMaintenanceMain }