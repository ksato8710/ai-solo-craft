#!/usr/bin/env python3
"""
è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿ çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜ã®è¨˜äº‹ä½œæˆcronã«XæŠ•ç¨¿æ©Ÿèƒ½ã‚’çµ±åˆã™ã‚‹ä¾‹
è¨˜äº‹ä½œæˆå®Œäº†å¾Œã€è‡ªå‹•çš„ã«å¯¾å¿œã™ã‚‹XæŠ•ç¨¿ã‚’å®Ÿè¡Œ

ä½¿ç”¨æ–¹æ³•:
python3 article_with_x_post.py --create-and-post
python3 article_with_x_post.py --article-id 123 --post-only
"""

import os
import sys
import json
import subprocess
from datetime import datetime

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = "/Users/satokeita/dev/ai-navigator"
SCRIPTS_DIR = os.path.join(BASE_DIR, "scripts")

# x_post_manager.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹è¿½åŠ 
sys.path.append(SCRIPTS_DIR)

try:
    from x_post_manager import execute_article_post, generate_post_from_article
except ImportError:
    print("âŒ x_post_manager.py ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“")
    sys.exit(1)

def simulate_article_creation():
    """è¨˜äº‹ä½œæˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã«ç½®ãæ›ãˆã‚‹ï¼‰"""
    
    # å®Ÿéš›ã®AI Navigatorè¨˜äº‹ä½œæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ã“ã“ã«å®Ÿè£…
    # ç¾åœ¨ã¯ä¾‹ã¨ã—ã¦å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    
    sample_articles = [
        {
            "title": "Claude 3.5 Sonnetã®æ–°æ©Ÿèƒ½å¾¹åº•è§£èª¬",
            "category": "dev-knowledge",
            "url": "https://ai.essential-navigator.com/claude-3-5-sonnet-new-features",
            "description": "Anthropic ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ« Claude 3.5 Sonnet ã®æ–°æ©Ÿèƒ½ã‚’è©³ç´°ã«è§£æã€‚å¾“æ¥ç‰ˆã¨ã®æ€§èƒ½æ¯”è¼ƒã¨å®Ÿç”¨çš„ãªæ´»ç”¨æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚",
            "created_at": datetime.now().isoformat()
        },
        {
            "title": "æ–°ã—ã„AIç”»åƒç”Ÿæˆãƒ„ãƒ¼ãƒ«ã€ŒImageForgeã€ãƒ¬ãƒ“ãƒ¥ãƒ¼",
            "category": "news",
            "url": "https://ai.essential-navigator.com/imageforge-review",
            "description": "å•†ç”¨åˆ©ç”¨å¯èƒ½ãªæ–°ã—ã„AIç”»åƒç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ ImageForge ã‚’å®Ÿéš›ã«ä½¿ç”¨ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚æ–™é‡‘ãƒ—ãƒ©ãƒ³ã¨ç«¶åˆã‚µãƒ¼ãƒ“ã‚¹ã¨ã®æ¯”è¼ƒåˆ†æã€‚",
            "created_at": datetime.now().isoformat()
        },
        {
            "title": "OpenAI DevDay 2024 é‡è¦ç™ºè¡¨ã¾ã¨ã‚",
            "category": "news",
            "url": "https://ai.essential-navigator.com/openai-devday-2024-summary",
            "description": "OpenAI DevDay 2024 ã§ç™ºè¡¨ã•ã‚ŒãŸæ–°æ©Ÿèƒ½ã¨ API æ›´æ–°æƒ…å ±ã‚’æ•´ç†ã€‚é–‹ç™ºè€…å‘ã‘ã®é‡è¦ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’è§£èª¬ã—ã¾ã™ã€‚",
            "created_at": datetime.now().isoformat()
        }
    ]
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤é¸æŠï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯è¨˜äº‹ä½œæˆãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    import random
    return random.choice(sample_articles)

def get_existing_article(article_id):
    """æ—¢å­˜è¨˜äº‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã«ç½®ãæ›ãˆã‚‹ï¼‰"""
    
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    # ç¾åœ¨ã¯ä¾‹ã¨ã—ã¦å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    
    return {
        "id": article_id,
        "title": f"è¨˜äº‹ID {article_id} ã®ã‚¿ã‚¤ãƒˆãƒ«",
        "category": "news",
        "url": f"https://ai.essential-navigator.com/article-{article_id}",
        "description": f"è¨˜äº‹ID {article_id} ã®èª¬æ˜æ–‡ã§ã™ã€‚",
        "created_at": datetime.now().isoformat()
    }

def log_workflow_result(article_data, post_success, error_message=None):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œçµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    
    log_file = os.path.join(BASE_DIR, "workflow_log.json")
    
    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "article": {
            "title": article_data.get("title", ""),
            "url": article_data.get("url", ""),
            "category": article_data.get("category", "")
        },
        "x_post": {
            "success": post_success,
            "error": error_message
        }
    }
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
    logs = []
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
        except:
            logs = []
    
    logs.append(log_entry)
    
    # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
    if len(logs) > 100:
        logs = logs[-100:]
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)

def create_article_and_post():
    """è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿ã®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    print("=== è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿ çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹ ===")
    
    # Step 1: è¨˜äº‹ä½œæˆ
    print("\nğŸ“ è¨˜äº‹ä½œæˆä¸­...")
    try:
        article_data = simulate_article_creation()
        if not article_data:
            print("è¨˜äº‹ä½œæˆãªã— - å‡¦ç†çµ‚äº†")
            return False
        
        print(f"âœ… è¨˜äº‹ä½œæˆå®Œäº†: {article_data['title']}")
        print(f"   URL: {article_data['url']}")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {article_data['category']}")
        
    except Exception as e:
        print(f"âŒ è¨˜äº‹ä½œæˆå¤±æ•—: {e}")
        return False
    
    # Step 2: XæŠ•ç¨¿å®Ÿè¡Œ
    print(f"\nğŸ“± XæŠ•ç¨¿æº–å‚™ä¸­...")
    try:
        # æŠ•ç¨¿å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        post_content = generate_post_from_article(article_data)
        print(f"æŠ•ç¨¿å†…å®¹:\n{post_content}\n")
        
        # æŠ•ç¨¿å®Ÿè¡Œ
        post_success = execute_article_post(article_data)
        
        # çµæœãƒ­ã‚°è¨˜éŒ²
        log_workflow_result(article_data, post_success)
        
        if post_success:
            print("âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†: è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿æˆåŠŸ")
        else:
            print("âš ï¸ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼éƒ¨åˆ†å®Œäº†: è¨˜äº‹ä½œæˆæˆåŠŸã€XæŠ•ç¨¿ã¯å¾…æ©Ÿãƒªã‚¹ãƒˆã«è¿½åŠ ")
        
        return True
        
    except Exception as e:
        print(f"âŒ XæŠ•ç¨¿å‡¦ç†å¤±æ•—: {e}")
        log_workflow_result(article_data, False, str(e))
        return False

def post_existing_article(article_id):
    """æ—¢å­˜è¨˜äº‹ã®XæŠ•ç¨¿ã®ã¿ã‚’å®Ÿè¡Œ"""
    
    print(f"=== è¨˜äº‹ID {article_id} ã®XæŠ•ç¨¿å®Ÿè¡Œ ===")
    
    try:
        # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿å–å¾—
        article_data = get_existing_article(article_id)
        print(f"è¨˜äº‹: {article_data['title']}")
        
        # XæŠ•ç¨¿å®Ÿè¡Œ
        post_success = execute_article_post(article_data)
        
        if post_success:
            print(f"âœ… XæŠ•ç¨¿å®Œäº†: {article_data['title']}")
        else:
            print(f"âš ï¸ XæŠ•ç¨¿ã¯å¾…æ©Ÿãƒªã‚¹ãƒˆã«è¿½åŠ : {article_data['title']}")
        
        return post_success
        
    except Exception as e:
        print(f"âŒ å‡¦ç†å¤±æ•—: {e}")
        return False

def check_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª"""
    
    print("=== ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª ===")
    
    # Browser RelayçŠ¶æ…‹
    try:
        result = subprocess.run(['browser', 'status', 'profile=chrome'], 
                              capture_output=True, text=True, timeout=10)
        if 'running: true' in result.stdout:
            print("âœ… Browser Relay: åˆ©ç”¨å¯èƒ½")
        else:
            print("âŒ Browser Relay: åˆ©ç”¨ä¸å¯")
    except:
        print("âŒ Browser Relay: æ¥ç¶šã‚¨ãƒ©ãƒ¼")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    pending_file = os.path.join(BASE_DIR, "X_PENDING_POSTS.md")
    if os.path.exists(pending_file):
        with open(pending_file, 'r') as f:
            content = f.read()
            pending_count = content.count('### ') - 1 if '###' in content else 0
        print(f"ğŸ“‹ å¾…æ©Ÿã‚¿ã‚¹ã‚¯: {pending_count}ä»¶")
    else:
        print("ğŸ“‹ å¾…æ©Ÿã‚¿ã‚¹ã‚¯: ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    log_file = os.path.join(BASE_DIR, "workflow_log.json")
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r') as f:
                logs = json.load(f)
            recent_logs = [log for log in logs if log['timestamp'].startswith(datetime.now().strftime('%Y-%m-%d'))]
            print(f"ğŸ“Š æœ¬æ—¥ã®å®Ÿè¡Œãƒ­ã‚°: {len(recent_logs)}ä»¶")
        except:
            print("ğŸ“Š ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
    else:
        print("ğŸ“Š ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: ãªã—")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿ çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('--create-and-post', action='store_true', help='è¨˜äº‹ä½œæˆ + XæŠ•ç¨¿å®Ÿè¡Œ')
    parser.add_argument('--article-id', help='æ—¢å­˜è¨˜äº‹ã®ID')
    parser.add_argument('--post-only', action='store_true', help='XæŠ•ç¨¿ã®ã¿å®Ÿè¡Œï¼ˆ--article-idã¨ä½µç”¨ï¼‰')
    parser.add_argument('--status', action='store_true', help='ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª')
    parser.add_argument('--preview', help='è¨˜äº‹ãƒ‡ãƒ¼ã‚¿JSONæ–‡å­—åˆ—ã®æŠ•ç¨¿å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼')
    
    args = parser.parse_args()
    
    if args.status:
        check_system_status()
        return
    
    if args.preview:
        try:
            article_data = json.loads(args.preview)
            post_content = generate_post_from_article(article_data)
            print("=== æŠ•ç¨¿å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ===")
            print(post_content)
        except Exception as e:
            print(f"âŒ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å¤±æ•—: {e}")
        return
    
    if args.create_and_post:
        success = create_article_and_post()
        sys.exit(0 if success else 1)
    
    if args.post_only and args.article_id:
        success = post_existing_article(args.article_id)
        sys.exit(0 if success else 1)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä½¿ç”¨æ³•è¡¨ç¤º
    parser.print_help()

if __name__ == '__main__':
    main()
