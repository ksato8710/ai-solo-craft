#!/usr/bin/env python3
"""
XæŠ•ç¨¿ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - è¨˜äº‹ä½œæˆcronã¨ã®é€£æºç”¨

æ©Ÿèƒ½:
- è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰XæŠ•ç¨¿å†…å®¹ã‚’è‡ªå‹•ç”Ÿæˆ
- Browser Relayã§ã®æŠ•ç¨¿å®Ÿè¡Œ
- å¤±æ•—æ™‚ã®Taskãƒªã‚¹ãƒˆç®¡ç†
- å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã®æ‰‹å‹•å®Ÿè¡Œæ”¯æ´

ä½¿ç”¨æ–¹æ³•:
python3 x_post_manager.py --article-data article.json --execute
python3 x_post_manager.py --list-pending
python3 x_post_manager.py --execute-pending
"""

import os
import sys
import json
import subprocess
from datetime import datetime
import re

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š
BASE_DIR = "/Users/satokeita/Dev/ai-solo-builder"
PENDING_FILE = os.path.join(BASE_DIR, "X_PENDING_POSTS.md")
COMPLETED_FILE = os.path.join(BASE_DIR, "X_COMPLETED_POSTS.md")
FAILED_FILE = os.path.join(BASE_DIR, "X_FAILED_POSTS.md")

# ã‚«ãƒ†ã‚´ãƒªæ­£è¦åŒ–ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›ï¼‰
LEGACY_CATEGORY_MAP = {
    # canonical
    'morning-summary': 'morning-summary',
    'evening-summary': 'evening-summary',
    'news': 'news',
    'dev-knowledge': 'dev-knowledge',
    'case-study': 'case-study',
    'products': 'products',
    # legacy -> canonical
    'morning-news': 'morning-summary',
    'evening-news': 'evening-summary',
    'product-news': 'news',
    'tools': 'news',
    'tool-review': 'news',
    'knowledge': 'dev-knowledge',
    'dev': 'dev-knowledge',
    'deep-dive': 'dev-knowledge',
    'featured-tools': 'dev-knowledge',
    'technical': 'dev-knowledge',
    'comparison': 'dev-knowledge',
}

def normalize_category(category: str) -> str:
    return LEGACY_CATEGORY_MAP.get(category, category)

# ãƒˆãƒ¼ãƒ³æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç—›ã€…ã—ã„è¡¨ç¾ã®é™¤å»ï¼‰
TONE_FIXES = [
    (r'([ï¼!]){2,}', 'ã€‚'),
    (r'å§‹å‹•[ï¼!]*', 'ã§ã™'),
    (r'ãŠå¾…ãŸã›ã—ã¾ã—ãŸ[ã€‚ï¼!]*', ''),
    (r'é©æ–°çš„[ãªã®]*', 'æ–°ã—ã„'),
    (r'å·®åˆ¥åŒ–', 'ç‰¹å¾´'),
    (r'æˆ¦ç•¥[çš„ã«]*', ''),
    (r'ã™ã”ã„[ã§ã™ï¼!]*', 'å„ªç§€ã§ã™'),
    (r'ã‚„ã°ã„[ã§ã™ï¼!]*', 'æ³¨ç›®ã™ã¹ãã§ã™'),
    (r'ç¥ãƒ„ãƒ¼ãƒ«', 'å„ªç§€ãªãƒ„ãƒ¼ãƒ«'),
    (r'\n{3,}', '\n\n'),
]

def improve_tone(text):
    """æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ãƒ³ã‚’æ”¹å–„"""
    result = text
    for pattern, replacement in TONE_FIXES:
        result = re.sub(pattern, replacement, result)
    return result.strip()

def generate_post_from_article(article_data):
    """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰XæŠ•ç¨¿å†…å®¹ã‚’è‡ªå‹•ç”Ÿæˆ"""
    
    title = article_data.get('title', '')
    category = normalize_category(article_data.get('category', 'unknown'))
    url = article_data.get('url', '')
    description = article_data.get('description', '')
    
    # URLã®èª¿æ•´ï¼ˆai.essential-navigator.comå½¢å¼ã«ï¼‰
    if url.startswith('https://'):
        url_display = url.replace('https://', '').replace('http://', '')
    else:
        url_display = f"ai.essential-navigator.com/{url}"
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥æŠ•ç¨¿ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    if category in ['dev-knowledge']:
        # æŠ€è¡“è§£èª¬
        post_content = f"""ğŸ”¬ã€æŠ€è¡“è§£æã€‘{title}

è©³ç´°åˆ†æã‚’è¨˜äº‹ã§å…¬é–‹ğŸ“Š

{description[:50]}...

è¨˜äº‹: {url_display}

#AIãƒ„ãƒ¼ãƒ« #æŠ€è¡“è§£èª¬"""
    
    elif category in ['morning-summary', 'evening-summary', 'news']:
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹
        post_content = f"""ğŸ“°ã€AIé€Ÿå ±ã€‘{title}

è©³ç´°ã‚’ã¾ã¨ã‚ã¾ã—ãŸğŸ—ï¸

{description[:50]}...

{url_display}

#AIæœ€æ–°æƒ…å ±"""
    
    elif category in ['case-study']:
        # äº‹ä¾‹ãƒ»æ¯”è¼ƒ
        post_content = f"""ğŸ“Šã€åˆ†æã€‘{title}

è¨˜äº‹ã§è©³ã—ãè§£èª¬ğŸ“

{description[:50]}...

{url_display}

#AIãƒ„ãƒ¼ãƒ« #äº‹ä¾‹åˆ†æ"""
    
    elif category in ['products']:
        # ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆè¾æ›¸ï¼ˆåŸå‰‡ã¯XæŠ•ç¨¿ã—ãªã„æƒ³å®šã€‚å¿…è¦ãªã‚‰æ‰‹å‹•ã§èª¿æ•´ï¼‰
        post_content = f"""ğŸ·ï¸ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆæ›´æ–°ã€‘{title}

æ¦‚è¦ã‚’æ›´æ–°ã—ã¾ã—ãŸğŸ“

{description[:50]}...

{url_display}"""
    
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        post_content = f"""{title}

è¨˜äº‹ã‚’å…¬é–‹ã—ã¾ã—ãŸğŸ“

{description[:50]}...

{url_display}

#AIãƒ„ãƒ¼ãƒ«"""
    
    # ãƒˆãƒ¼ãƒ³æ”¹å–„
    return improve_tone(post_content)

def is_browser_relay_available():
    """Browser Relayã®åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
    try:
        result = subprocess.run(['browser', 'status', 'profile=chrome'], 
                              capture_output=True, text=True, timeout=10)
        return 'running: true' in result.stdout and 'cdpReady: true' in result.stdout
    except:
        return False

def execute_x_post_with_browser_relay(post_content):
    """Browser Relayã§XæŠ•ç¨¿ã‚’å®Ÿè¡Œ"""
    
    if not is_browser_relay_available():
        raise Exception("Browser Relay not available")
    
    # JavaScriptç”¨ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
    content_js = json.dumps(post_content)[1:-1]
    
    try:
        # æŠ•ç¨¿ç”»é¢ã«ç§»å‹•
        result1 = subprocess.run([
            'browser', 'navigate', 'profile=chrome', 
            'targetUrl=https://x.com/compose/post'
        ], capture_output=True, text=True, timeout=30)
        
        if result1.returncode != 0:
            raise Exception(f"Navigation failed: {result1.stderr}")
        
        # ã‚¿ãƒ–IDå–å¾—
        tabs_result = subprocess.run([
            'browser', 'tabs', 'profile=chrome'
        ], capture_output=True, text=True, timeout=10)
        
        if tabs_result.returncode != 0:
            raise Exception("Failed to get tabs")
        
        # ç°¡æ˜“çš„ã«ã‚¿ãƒ–IDã‚’æŠ½å‡ºï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ JSON parsingæ¨å¥¨ï¼‰
        tab_lines = tabs_result.stdout.split('\n')
        target_id = None
        for line in tab_lines:
            if 'x.com' in line and 'targetId' in line:
                # targetId ã‚’æŠ½å‡º
                parts = line.split('"')
                for i, part in enumerate(parts):
                    if part == 'targetId':
                        target_id = parts[i+2]
                        break
                break
        
        if not target_id:
            raise Exception("Could not find X.com tab")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        js_command = f'const textarea = document.querySelector(\'[data-testid="tweetTextarea_0"]\'); if(textarea) {{ textarea.textContent = \'{content_js}\'; textarea.dispatchEvent(new Event(\'input\', {{bubbles: true}})); return \'text_entered\'; }} else {{ return \'textarea_not_found\'; }}'
        
        result2 = subprocess.run([
            'browser', 'act', f'targetId={target_id}',
            f'request={{"kind": "evaluate", "fn": "{js_command}"}}'
        ], capture_output=True, text=True, timeout=20)
        
        if 'text_entered' not in result2.stdout:
            raise Exception("Text input failed")
        
        # æŠ•ç¨¿å®Ÿè¡Œ
        click_command = 'const btn = document.querySelector(\'[data-testid="tweetButton"]\'); if(btn && !btn.disabled) { btn.click(); return \'posted\'; } else { return \'button_disabled\'; }'
        
        result3 = subprocess.run([
            'browser', 'act', f'targetId={target_id}',
            f'request={{"kind": "evaluate", "fn": "{click_command}"}}'
        ], capture_output=True, text=True, timeout=20)
        
        if 'posted' in result3.stdout:
            return True
        else:
            raise Exception("Post button was disabled or click failed")
    
    except Exception as e:
        raise Exception(f"Browser Relay execution failed: {e}")

def add_to_pending_tasks(article_data, post_content, reason="unknown"):
    """æœªæŠ•ç¨¿ã‚¿ã‚¹ã‚¯ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ """
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    title = article_data.get('title', 'ç„¡é¡Œ')
    url = article_data.get('url', '')
    category = normalize_category(article_data.get('category', 'unknown'))
    
    # å„ªå…ˆåº¦è¨­å®š
    priority_map = {
        'morning-summary': 'é«˜ï¼ˆé€Ÿå ±æ€§ï¼‰',
        'evening-summary': 'é«˜ï¼ˆé€Ÿå ±æ€§ï¼‰',
        'news': 'é«˜ï¼ˆé€Ÿå ±æ€§ï¼‰',
        'dev-knowledge': 'ä¸­ï¼ˆè§£èª¬ç³»ï¼‰',
        'case-study': 'ä½ï¼ˆäº‹ä¾‹ç³»ï¼‰',
        'products': 'ä½ï¼ˆè¾æ›¸ï¼‰',
    }
    priority = priority_map.get(category, 'ä¸­')
    
    # æœŸé™è¨­å®š
    deadline_map = {
        'morning-summary': '6æ™‚é–“ä»¥å†…',
        'evening-summary': '6æ™‚é–“ä»¥å†…',
        'news': '6æ™‚é–“ä»¥å†…',
        'dev-knowledge': '2æ—¥ä»¥å†…',
        'case-study': '1é€±é–“ä»¥å†…',
        'products': '1é€±é–“ä»¥å†…',
    }
    deadline = deadline_map.get(category, '2æ—¥ä»¥å†…')
    
    task_entry = f"""
### {timestamp} - {category}è¨˜äº‹
- **è¨˜äº‹:** [{title}]({url})
- **æŠ•ç¨¿å†…å®¹:**
  ```
  {post_content}
  ```
- **ç†ç”±:** {reason}
- **å„ªå…ˆåº¦:** {priority}
- **æœŸé™:** {deadline}
"""
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
    os.makedirs(os.path.dirname(PENDING_FILE), exist_ok=True)
    
    if not os.path.exists(PENDING_FILE):
        with open(PENDING_FILE, 'w', encoding='utf-8') as f:
            f.write("# XæŠ•ç¨¿å¾…æ©Ÿãƒªã‚¹ãƒˆ\n\n## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰\n")
    
    # æœªæŠ•ç¨¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«è¿½è¨˜
    with open(PENDING_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # "## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰" ã®å¾Œã«æŒ¿å…¥
    if "## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰" in content:
        parts = content.split("## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰")
        if len(parts) > 1:
            # æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
            next_section = parts[1].split("## ")[0] if "## " in parts[1] else parts[1]
            remaining = parts[1][len(next_section):] if "## " in parts[1] else ""
            
            new_content = parts[0] + "## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰" + next_section + task_entry
            if remaining:
                new_content += "## " + remaining
        else:
            new_content = content + task_entry
    else:
        new_content = content + "\n## æœªæŠ•ç¨¿ï¼ˆè¦æ‰‹å‹•å®Ÿè¡Œï¼‰\n" + task_entry
    
    with open(PENDING_FILE, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"âœ… æŠ•ç¨¿ã‚¿ã‚¹ã‚¯ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ : {title}")

def log_successful_post(article_data, post_content):
    """æŠ•ç¨¿æˆåŠŸã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
    title = article_data.get('title', 'ç„¡é¡Œ')
    url = article_data.get('url', '')
    
    log_entry = f"""
### {timestamp} - æŠ•ç¨¿æˆåŠŸ
- **è¨˜äº‹:** [{title}]({url})
- **æŠ•ç¨¿å†…å®¹:** {post_content[:50]}...
- **æŠ•ç¨¿æ™‚åˆ»:** {timestamp}
"""
    
    os.makedirs(os.path.dirname(COMPLETED_FILE), exist_ok=True)
    
    if not os.path.exists(COMPLETED_FILE):
        with open(COMPLETED_FILE, 'w', encoding='utf-8') as f:
            f.write("# XæŠ•ç¨¿å®Œäº†ãƒ­ã‚°\n\n")
    
    with open(COMPLETED_FILE, 'a', encoding='utf-8') as f:
        f.write(log_entry)
    
    print(f"âœ… æŠ•ç¨¿å®Œäº†ãƒ­ã‚°ã«è¨˜éŒ²: {title}")

def execute_article_post(article_data):
    """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰XæŠ•ç¨¿ã‚’å®Ÿè¡Œï¼ˆãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼‰"""
    
    if not article_data:
        print("è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return False
    
    # æŠ•ç¨¿å†…å®¹ç”Ÿæˆ
    post_content = generate_post_from_article(article_data)
    print(f"ç”Ÿæˆã•ã‚ŒãŸæŠ•ç¨¿å†…å®¹:\n{post_content}\n")
    
    # Browser Relay ã§ã®æŠ•ç¨¿å®Ÿè¡Œã‚’è©¦è¡Œ
    try:
        if is_browser_relay_available():
            print("Browser Relay ã§ã®æŠ•ç¨¿ã‚’å®Ÿè¡Œä¸­...")
            execute_x_post_with_browser_relay(post_content)
            log_successful_post(article_data, post_content)
            print(f"âœ… XæŠ•ç¨¿å®Œäº†: {article_data.get('title', 'ç„¡é¡Œ')}")
            return True
        else:
            print("âš ï¸ Browser Relayåˆ©ç”¨ä¸å¯ - Taskãƒªã‚¹ãƒˆã«è¿½åŠ ")
            add_to_pending_tasks(article_data, post_content, reason="browser_relay_unavailable")
            return False
    except Exception as e:
        print(f"âš ï¸ æŠ•ç¨¿å®Ÿè¡Œå¤±æ•—: {e}")
        add_to_pending_tasks(article_data, post_content, reason=f"error: {e}")
        return False

def list_pending_tasks():
    """å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯ä¸€è¦§è¡¨ç¤º"""
    
    if not os.path.exists(PENDING_FILE):
        print("æœªæŠ•ç¨¿ã‚¿ã‚¹ã‚¯ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    with open(PENDING_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print("=== æœªæŠ•ç¨¿ã‚¿ã‚¹ã‚¯ä¸€è¦§ ===")
    print(content)

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='XæŠ•ç¨¿ç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('--article-data', help='è¨˜äº‹ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--article-json', help='è¨˜äº‹ãƒ‡ãƒ¼ã‚¿JSONæ–‡å­—åˆ—')
    parser.add_argument('--execute', action='store_true', help='æŠ•ç¨¿ã‚’å®Ÿè¡Œ')
    parser.add_argument('--list-pending', action='store_true', help='å¾…æ©Ÿã‚¿ã‚¹ã‚¯ã‚’ä¸€è¦§è¡¨ç¤º')
    parser.add_argument('--test-content', help='æŠ•ç¨¿å†…å®¹ãƒ†ã‚¹ãƒˆ')
    
    args = parser.parse_args()
    
    if args.list_pending:
        list_pending_tasks()
        return
    
    if args.test_content:
        improved = improve_tone(args.test_content)
        print("=== ãƒˆãƒ¼ãƒ³æ”¹å–„çµæœ ===")
        print(improved)
        return
    
    # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿å–å¾—
    article_data = None
    
    if args.article_data and os.path.exists(args.article_data):
        with open(args.article_data, 'r', encoding='utf-8') as f:
            article_data = json.load(f)
    elif args.article_json:
        article_data = json.loads(args.article_json)
    else:
        print("è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (--article-data ã¾ãŸã¯ --article-json)")
        return
    
    if args.execute:
        execute_article_post(article_data)
    else:
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
        post_content = generate_post_from_article(article_data)
        print("=== ç”Ÿæˆã•ã‚Œã‚‹æŠ•ç¨¿å†…å®¹ ===")
        print(post_content)

if __name__ == '__main__':
    main()
