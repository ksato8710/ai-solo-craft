---
slug: arxiv-klong-long-horizon-agent-2026-02-23
title: 【arXiv速報】KLong：超長期タスクを解決するオープンソースLLMエージェント—Kimi K2を11%超え
description: >-
  研究論文再現タスクでKimi K2 Thinking (1T)を11.28%上回る106Bパラメータモデル。Progressive
  RLと軌道分割SFTで長期間にわたる複雑なタスクを自律的に完遂。ソロビルダーのワークフロー自動化に革命的な示唆。
date: '2026-02-23'
readTime: 6
featured: false
category: news
tags:
  - arXiv論文
  - AIエージェント
  - 開発ツール
contentType: news
image: /thumbnails/arxiv-klong-long-horizon-agent-2026-02-23.png
---

## 要点

長期間のタスク（数時間〜数日かかる複雑な作業）を自律的に解決できるAIエージェント「KLong」が登場。オープンソースで公開され、クローズドモデルのKimi K2 Thinking (1Tパラメータ)を11.28%上回る性能を達成した。

## NVA評価

| 観点 | スコア | 理由 |
|------|--------|------|
| 新規性 (Novelty) | ★★★★☆ | Progressive RLによる段階的タイムアウト延長は新しいアプローチ |
| 実用性 (Value) | ★★★★★ | 長期タスク自動化はソロビルダーの生産性を劇的に向上させる |
| 実現度 (Accessibility) | ★★★★☆ | 106Bモデルは大きいが、蒸留やAPI経由での利用を期待 |
| **総合** | **4.3/5** | **即座に活用可能ではないが、近い将来のワークフローを変える** |

## 何が新しいのか

### 1. Progressive RL（段階的強化学習）

従来のRLでは短いタスクでしか訓練できなかった。KLongは**タイムアウトを段階的に延長**しながら訓練することで、数時間〜数日かかるタスクでも安定して学習できる。

```
Stage 1: 30分タイムアウト → 基礎スキル習得
Stage 2: 2時間タイムアウト → 中期タスク対応
Stage 3: 8時間タイムアウト → 長期タスク完遂
```

### 2. 軌道分割SFT（Trajectory-Splitting SFT）

Claude 4.5 Sonnet (Thinking)から蒸留した超長い軌道データを、**オーバーラップを持たせて分割**して学習。早期の文脈を保持しながら、長大な作業履歴を効率的に学習できる。

### 3. Research-Factory パイプライン

arXiv論文を収集し、再現タスクと評価ルブリックを自動生成する仕組み。これにより高品質な訓練データを大量に生成できる。

## ベンチマーク結果

| ベンチマーク | KLong (106B) | Kimi K2 (1T) | 改善 |
|-------------|-------------|--------------|------|
| **PaperBench** | 34.5% | 23.2% | **+11.28pt** |
| SWE-bench Verified | 58.2% | - | 競争力あり |
| MLE-bench | 42.1% | - | 競争力あり |

## ソロビルダーへの示唆

### 1. 「寝ている間に完成」が現実に

長期タスクを任せられるエージェントが実現すれば：

- 夜間にフルスタックアプリのプロトタイプ生成
- 週末中にドキュメント整備と翻訳
- 複数日かけたリファクタリングプロジェクト

### 2. 品質保証付きの自動化

Progressive RLで訓練されたエージェントは、**途中で迷子にならない**。これまでのAIエージェントの「途中で止まる」「変な方向に進む」問題が軽減される。

### 3. 研究論文の実装自動化

Research-Factoryの仕組みは、最新論文をすぐにプロダクトに組み込む高速サイクルを可能にする。

## 今日からできること

1. **タスク分解の練習** — 長期タスクを自然言語で明確に定義する習慣をつける
2. **評価基準の明文化** — 「何をもって完了とするか」を具体的に書く
3. **Claude Code/Cursor**で段階的な自動化を試す — KLong的なアプローチの擬似体験

## 技術詳細

- **モデルサイズ**: 106Bパラメータ
- **訓練データソース**: Claude 4.5 Sonnet (Thinking)からの蒸留
- **文脈管理**: シンプルなOverlapping Windowで実装
- **報酬設計**: ルブリックベースの評価モデル

GitHub: [https://github.com/david3684/flm](https://github.com/david3684/flm) (論文内リンク、正式リポジトリは公開待ち)

---

*arXiv Daily (rosinality.substack.com) 2026-02-20号より抜粋・解説*
